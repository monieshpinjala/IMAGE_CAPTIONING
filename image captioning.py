# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1liA3rIAqrOJMs7-odOom36ASVu_sZwv6
"""

import numpy as np
import pandas as pd
import os

path_img = '../input/flickr-8k-images-with-captions/Images'
jpgs = os.listdir(path_img)
print(f"All jpgs count: {len(jpgs)}\n")
jpgs[:100]

def load_txt(path_txt):
    #open file as read only
    file = open(path_txt, 'r')
    #read all text
    text = file.read()
    #close file
    file.close()
    return text

path_txt = '../input/flickr8k-text/flickr8k.token.txt'
#loading descriptions
text_doc = load_txt(path_txt)

print(text_doc[:500])

#reading above text file line after line
txt = []
for line in text_doc.split('\n'): #splitting everyline using '/n'

    spliting_every_line = line.split() #dtype : list
    #special cases handling
    if len(spliting_every_line) == 0:
        continue
  ]
    imageName_captionNum_of_all_line = []

    imageName_captionNum_of_all_line.append(spliting_every_line[0])
   ]
    imageName_captionNum_of_all_line.append(" ".join(spliting_every_line[1:]))

    #spliting using "#"
    imgName_num_seprated = imageName_captionNum_of_all_line[0].split('#')
    #appending to above list names as txt
    txt.append(imgName_num_seprated + [imageName_captionNum_of_all_line[1].lower()])


#making text dataframe out of raw text
text_df = pd.DataFrame(txt,columns=['image_name','image_index','image_caption'])
#reindexing
text_df_reindexed = text_df.reindex(columns = ['image_index','image_name','image_caption'])
text_df_reindexed_1 = text_df_reindexed[text_df_reindexed.image_caption != '2258277193_586949ec62.jpg.1']
uni_filename = np.unique(text_df_reindexed_1.image_name.values)

def load_text_doc(text_toke_data):
    mapping = dict()
    for line in text_toke_data.split('\n'):

        spliting_every_line_token = line.split()

        if len(line) < 2:
            continue


        image_id, image_desc = spliting_every_line_token[0], spliting_every_line_token[1:]

        image_id = image_id.split('.')[0]
        image_desc = ' '.join(image_desc)
        if image_id not in mapping:
            mapping[image_id] = list()

        #storing
        mapping[image_id].append(image_desc)
    return mapping

desc_dict = load_text_doc(text_doc)

print(f'Description Dictionary have :{len(desc_dict.keys())}: number of keys')

list(desc_dict.keys())[:100]

len(desc_dict['1000268201_693b08cb0e'])

desc_dict['1000268201_693b08cb0e']

desc_dict['1015584366_dfcec3c85a']

import string

#all punctuation  example
string.punctuation

#removing punctuation dummy
txt = 'A boy in a green shirt is looking down at many inflatable boats .'
mytable = txt.maketrans(" ", " ", string.punctuation)
print(txt.translate(mytable))

def clean_image_captions(description_dic):

    for key, image_captions in desc_dict.items():

        for element_in_image_caption in range(len(image_captions)):

            #accessing every element(token) of each image_caption related to key
            image_captions_elements = image_captions[element_in_image_caption]
            #putting every element(token) in seperate list
            image_captions_elements_list = image_captions_elements.split()
            #all in lower case
            image_captions_elements_list_lower_cased = [element.lower() for element in image_captions_elements_list]
            #removing punctuations if exist from each token
            image_captions_elements_punctuations_removed = [element.translate(str.maketrans('', '', string.punctuation)) for element in image_captions_elements_list_lower_cased]
            #removing elements/tokens/word if it's length is less then 1 ==> focus is to remove "s" & "a"
            image_captions_elements_word_cleaned = [element for element in image_captions_elements_punctuations_removed if len(element) > 1]

            #removing elements/tokens/word if they are alphanumeric ::: testing here can update later
            image_captions_elements_alphanum_removed = [element for element in image_captions_elements_word_cleaned if element.isalpha()]

            #storing final usefull image_captions as strings
            image_captions[element_in_image_caption] = ' '.join(image_captions_elements_alphanum_removed)

#calling function for work
clean_image_captions(desc_dict)

desc_dict['1000268201_693b08cb0e']

desc_dict['1015584366_dfcec3c85a']

def saving_processed_desc_dict(descriptions_dict, filename):
    lines = list()
    for key, desc_list in desc_dict.items():
        for desc in desc_dict:
            lines.append(key + ' ' + desc)
    data = '\n'.join(lines)
    file = open(filename, 'w')
    file.write(data)
    file.close()

saving_processed_desc_dict(desc_dict, 'desc_dict_with_processed_image_caption.txt')

def img_captions_vocabulary(descriptions):

    #set to store vocab which we will get out of image_captions of each key
    image_captions_vocabulary_set = set()

    for key in descriptions.keys():
        [image_captions_vocabulary_set.update(each_image_captions.split()) for each_image_captions in descriptions[key]]

    return image_captions_vocabulary_set

#storing vocabulary in variable
image_captions_vocabulary = img_captions_vocabulary(desc_dict)
print(f'Final image_captions_vocabulary Size: {len(image_captions_vocabulary)}')

def load_txt(path_txt):

    #open file as read only
    file = open(path_txt, 'r')
    #read all text
    text = file.read()
    #close file
    file.close()
    return text

#loading train data
train_path = '../input/flickr8k-text/'
train_data = load_txt(train_path+'flickr_8k.trainImages.txt')
print(train_data[:200])

def load_process_train_data(train_txt_file):
    train_data_final = list()

    #using above function to load train_data
    doc = load_txt(path_txt=train_txt_file)

    #spliting image names using `\n` and then accessing every image name
    for every_img_desc in doc.split('\n'):

        #to remove any empty string
        if len(every_img_desc) < 1:
            continue

        #removing `.jpg` extension or getting image id
        image_id = every_img_desc.split('.')[0]
        train_data_final.append(image_id)

    return set(train_data_final)

processed_train_data = load_process_train_data(train_txt_file=train_path+'flickr_8k.trainImages.txt') #dtype :: set
print(f'Total image_id in train_dataset are : {len(processed_train_data)}\n\n')


import random
#see any 5 image_id of train set
print(f"5 Randome train_id's: \n{random.sample(processed_train_data,5)}")

import glob

images_data_path = '../input/flickr-8k-images-with-captions/Images/'
every_image_full_path = glob.glob(images_data_path + '*.jpg')

type(every_image_full_path)

train_images_all = set(open(train_path+'flickr_8k.trainImages.txt', 'r').read().strip().split('\n'))

train_images_after_check = []
for particular_image_full_path in every_image_full_path:

    if particular_image_full_path[len(images_data_path):] in train_images_all:
        train_images_after_check.append(particular_image_full_path)

train_images_after_check[:3]

test_images_all = set(open(train_path+'flickr_8k.testImages.txt', 'r').read().strip().split('\n'))

test_images_after_check = []
for particular_image_full_path in every_image_full_path:

    if particular_image_full_path[len(images_data_path):] in test_images_all:
        test_images_after_check.append(particular_image_full_path)

test_images_after_check[:3]

path_txt = '../input/flickr8k-text/flickr8k.token.txt'

def load_txt(path_txt):
    file = open(path_txt, 'r')
    #read
    text = file.read()
    #close
    file.close()
    return text


def load_clean_descriptions(path_txt, dataset):
    doc = load_txt(path_txt)

    descriptions = dict()
    for line in doc.split('\n'):

        tokens = line.split()

        image_id, image_desc = tokens[0], tokens[1:]

        if image_id in dataset:

            if image_id not in descriptions:
                descriptions[image_id] = list()


            desc = 'start ' + ' '.join(image_desc) + ' end'
            #store
            descriptions[image_id].append(desc)
    return descriptions

train_descriptions = load_clean_descriptions('./desc_dict_with_processed_image_caption.txt', processed_train_data)
print(len(train_descriptions))

def preprocess(image_path):
    img = image.load_img(image_path, target_size=(299,299))
    x = image.img_array(img)
    x = np.expand_dims(x,axis=0)
    x = preprocess_input(x)
    return(x)

for i in range(8):
    print(i)
    for j in range(8):
        print(i)
        print(j)